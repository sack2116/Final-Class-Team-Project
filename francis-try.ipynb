{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c412925-a69b-44ef-955b-9c805fa466e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Purpose: AI Lyricist Project\n",
    "# This project aims to generate music lyrics using machine learning models. The system is designed to train on a dataset of song lyrics, learn patterns in word sequences, and generate new, coherent lyrics based on a seed phrase provided by the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7f63f2-2ed9-4d90-9c7d-ba32929891bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Preprocess Data\n",
    "\n",
    "def load_data(file_path, chunksize=10000):\n",
    "    \"\"\"\n",
    "    Load and process a large CSV file in chunks.\n",
    "\n",
    "    :param file_path: Path to the CSV file.\n",
    "    :param chunksize: Number of rows per chunk to process.\n",
    "    :return: Combined lyrics as a single text block.\n",
    "    \"\"\"\n",
    "    lyrics_list = []\n",
    "\n",
    "    # Read the CSV file in chunks\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        # Drop rows with missing lyrics in the current chunk\n",
    "        chunk = chunk.dropna(subset=['lyrics'])\n",
    "        # Append the lyrics to the list\n",
    "        lyrics_list.extend(chunk['lyrics'].tolist())\n",
    "\n",
    "    # Combine all lyrics into a single text block\n",
    "    lyrics = \"\\n\".join(lyrics_list)\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139e89ee-19fd-458e-8971-cda8855848b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Sequence Preparation\n",
    "def preprocess_text(text):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # Create input sequences\n",
    "    input_sequences = []\n",
    "    for line in text.split('\\n'):\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "\n",
    "    # Pad sequences\n",
    "    max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "    # Split into predictors and label\n",
    "    predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "    label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "    return predictors, label, max_sequence_len, total_words, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93996470-a019-4a58-a3f7-1dd4ea6d783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the Model\n",
    "def build_model(total_words, max_sequence_len):\n",
    "    model = Sequential([\n",
    "        Embedding(total_words, 64, input_length=max_sequence_len-1),\n",
    "        LSTM(100, return_sequences=True),\n",
    "        LSTM(100),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(total_words, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89243f05-54cb-492d-bab1-6f72dff4cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the Model\n",
    "def train_model(model, predictors, label, epochs=30):\n",
    "    model.fit(predictors, label, epochs=epochs, verbose=1)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0a08d4-6c9a-4c3e-8bd4-82b4aa1892c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate Lyrics\n",
    "def generate_lyrics(seed_text, model, tokenizer, max_sequence_len, num_words=20):\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                seed_text += \" \" + word\n",
    "                break\n",
    "\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6306c0-7e56-4144-a61f-052ef994c393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f8cd23-fc97-42fd-bf99-c5ef7f16c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main Workflow\n",
    "# if __name__ == \"__main__\":\n",
    "#     # File path to lyrics dataset (replace with actual file path)\n",
    "#     data_path = \"lyrics.csv\"\n",
    "# if os.path.exists(data_path):\n",
    "#     # Load and preprocess data\n",
    "#     data = load_data(data_path)\n",
    "#     predictors, label, max_sequence_len, total_words, tokenizer = preprocess_text(data)\n",
    "\n",
    "#     # Build and train the model\n",
    "#     model = build_model(total_words, max_sequence_len)\n",
    "#     model = train_model(model, predictors, label, epochs=30)\n",
    "\n",
    "#     # Launch Gradio Interface\n",
    "#     interface = gr.Interface(fn=predict_lyrics, \n",
    "#                               inputs=\"text\", \n",
    "#                               outputs=\"text\", \n",
    "#                               title=\"AI Lyric Generator\",\n",
    "#                               description=\"Enter a seed phrase to generate music lyrics.\")\n",
    "#     interface.launch()\n",
    "# else:\n",
    "#     print(f\"Dataset not found at {data_path}. Please provide a valid path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "089a1899",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Resources/lyrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Resources/lyrics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m lyrics \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m lyrics\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path, chunksize)\u001b[0m\n\u001b[1;32m      9\u001b[0m processed_chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Read the CSV file in chunks\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Drop rows with missing lyrics in the current chunk\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlyrics\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Append the processed chunk to the list\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Resources/lyrics.csv'"
     ]
    }
   ],
   "source": [
    "data_path = \"./Resources/lyrics.csv\"\n",
    "lyrics = load_data(data_path)\n",
    "lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47df8dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lyrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlyrics\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lyrics' is not defined"
     ]
    }
   ],
   "source": [
    "lyrics.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88aa4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266557"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe8624e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics['lyrics'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aefa6278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the lyrics\n",
    "lyrics['lyrics'] = lyrics['lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d42e901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searcher\n",
    "lyrics['lyrics'].str.contains('\\[verse', case=False).sum()\n",
    "4103 - 3915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2b0a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace function to remove any character\n",
    "def replaceLyricsChars(what, to, regex=False):\n",
    "    lyrics['lyrics'] = lyrics['lyrics'].str.replace(what, to, regex=regex)\n",
    "    return lyrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2012808e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?You know Im gonna cut r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin everything so easy,its like you seem so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you searchFor tendernessIt isnt hard to fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I[Verse 1:]If I wrote a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party its pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266552</th>\n",
       "      <td>224995</td>\n",
       "      <td>i-ii-never-fall-in-love-again</td>\n",
       "      <td>2006</td>\n",
       "      <td>ella-fitzgerald</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>What do you get when you fall in love?A guy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266553</th>\n",
       "      <td>224996</td>\n",
       "      <td>everything-but-you</td>\n",
       "      <td>2006</td>\n",
       "      <td>ella-fitzgerald</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>You left me a horse from Texas,A house with in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266554</th>\n",
       "      <td>224997</td>\n",
       "      <td>yesterdays</td>\n",
       "      <td>2006</td>\n",
       "      <td>ella-fitzgerald</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>I am not such a clever oneAbout the latest fad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266555</th>\n",
       "      <td>224998</td>\n",
       "      <td>over-the-rainbow</td>\n",
       "      <td>2006</td>\n",
       "      <td>ella-fitzgerald</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>Somewhere over the rainbow, way up highTheres ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266556</th>\n",
       "      <td>224999</td>\n",
       "      <td>jersey-bounce</td>\n",
       "      <td>2006</td>\n",
       "      <td>ella-fitzgerald</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>They call it that jersey bounceA rhythm that r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266557 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                           song  year           artist genre  \\\n",
       "0            0                      ego-remix  2009  beyonce-knowles   Pop   \n",
       "1            1                   then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2            2                        honesty  2009  beyonce-knowles   Pop   \n",
       "3            3                you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4            4                  black-culture  2009  beyonce-knowles   Pop   \n",
       "...        ...                            ...   ...              ...   ...   \n",
       "266552  224995  i-ii-never-fall-in-love-again  2006  ella-fitzgerald  Jazz   \n",
       "266553  224996             everything-but-you  2006  ella-fitzgerald  Jazz   \n",
       "266554  224997                     yesterdays  2006  ella-fitzgerald  Jazz   \n",
       "266555  224998               over-the-rainbow  2006  ella-fitzgerald  Jazz   \n",
       "266556  224999                  jersey-bounce  2006  ella-fitzgerald  Jazz   \n",
       "\n",
       "                                                   lyrics  \n",
       "0       Oh baby, how you doing?You know Im gonna cut r...  \n",
       "1       playin everything so easy,its like you seem so...  \n",
       "2       If you searchFor tendernessIt isnt hard to fin...  \n",
       "3       Oh oh oh I, oh oh oh I[Verse 1:]If I wrote a b...  \n",
       "4       Party the people, the people the party its pop...  \n",
       "...                                                   ...  \n",
       "266552  What do you get when you fall in love?A guy wi...  \n",
       "266553  You left me a horse from Texas,A house with in...  \n",
       "266554  I am not such a clever oneAbout the latest fad...  \n",
       "266555  Somewhere over the rainbow, way up highTheres ...  \n",
       "266556  They call it that jersey bounceA rhythm that r...  \n",
       "\n",
       "[266557 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaceLyricsChars('\\'', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totality: 266557 -> 0\n",
      "With Verse: 3915 -> 0\n"
     ]
    }
   ],
   "source": [
    "# show all lyrics that have the word 'verse'\n",
    "totality = len(lyrics)\n",
    "with_verse = len(lyrics[lyrics['lyrics'].str.contains('\\[verse', case=False)])\n",
    "replaceLyricsChars('\\[verse+\\]', '', regex=True)\n",
    "replaceLyricsChars('\\[verse*\\]', '', regex=True)\n",
    "\n",
    "delta_totality = totality - len(lyrics)\n",
    "delta_with_verse = with_verse - len(lyrics[lyrics['lyrics'].str.contains('\\[verse', case=False)])\n",
    "\n",
    "print(f\"Totality: {totality} -> {delta_totality}\")\n",
    "print(f\"With Verse: {with_verse} -> {delta_with_verse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd7a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totality: 266557 -> 0\n",
      "With intro: 735 -> 0\n"
     ]
    }
   ],
   "source": [
    "# show all lyrics that have the word 'intro'\n",
    "totality = len(lyrics)\n",
    "with_intro = len(lyrics[lyrics['lyrics'].str.contains('\\[intro', case=False)])\n",
    "replaceLyricsChars('\\[intro+\\]', '', regex=True)\n",
    "replaceLyricsChars('\\[intro*\\]', '', regex=True)\n",
    "\n",
    "delta_totality = totality - len(lyrics)\n",
    "delta_with_intro = with_intro - len(lyrics[lyrics['lyrics'].str.contains('\\[intro', case=False)])\n",
    "\n",
    "print(f\"Totality: {totality} -> {delta_totality}\")\n",
    "print(f\"With intro: {with_intro} -> {delta_with_intro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff85da8f-6e52-4e4b-b845-d08c59bdaad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0g/m_btl88n5hs7w95j59p7v2180000gn/T/ipykernel_38805/2075172157.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Load and preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlyrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Build and train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0g/m_btl88n5hs7w95j59p7v2180000gn/T/ipykernel_38805/1940501176.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Create input sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    289\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                     seq = text_to_word_sequence(\n\u001b[0m\u001b[1;32m    294\u001b[0m                         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                         \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                         \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/keras/preprocessing/text.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtranslate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtranslate_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictors, label, max_sequence_len, total_words, tokenizer = preprocess_text(lyrics)\n",
    "\n",
    "# Build and train the model\n",
    "model = build_model(total_words, max_sequence_len)\n",
    "model = train_model(model, predictors, label, epochs=30)\n",
    "\n",
    "# Generate new lyrics\n",
    "seed_text = \"love is a beautiful\"\n",
    "generated_lyrics = generate_lyrics(seed_text, model, tokenizer, max_sequence_len, num_words=50)\n",
    "print(\"Generated Lyrics:\")\n",
    "print(generated_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a1c35b-daef-4354-830b-a28c1007001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(file_path, chunksize=10000):\n",
    "    \"\"\"\n",
    "    Load and process a large CSV file in chunks.\n",
    "\n",
    "    :param file_path: Path to the CSV file.\n",
    "    :param chunksize: Number of rows per chunk to process.\n",
    "    :return: A single DataFrame containing the processed data.\n",
    "    \"\"\"\n",
    "    processed_chunks = []\n",
    "\n",
    "    # Read the CSV file in chunks\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        # Drop rows with missing lyrics in the current chunk\n",
    "        chunk = chunk.dropna(subset=['lyrics'])\n",
    "        # Append the processed chunk to the list\n",
    "        processed_chunks.append(chunk)\n",
    "\n",
    "    # Concatenate all chunks into a single DataFrame\n",
    "    combined_data = pd.concat(processed_chunks, ignore_index=True)\n",
    "    return combined_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
