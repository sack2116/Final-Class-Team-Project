{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utilities import replaceLyricsChars, load_data, searchLyrics\n",
    "from splitter import join_csv\n",
    "# use >> python splitter.py to join all the lyrics of Resources folder into one file, after you load it, please, delete the lyrics.csv created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_csv_path = \"./Resources/lyrics.csv\"\n",
    "join_csv(\"./Resources/lyrics_chunks/\", dirty_csv_path)\n",
    "lyrics_df = load_data(dirty_csv_path)\n",
    "\n",
    "# delete the file\n",
    "os.remove(dirty_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics_df(df):\n",
    "    df = df.dropna()\n",
    "    df['lyrics'] = df['lyrics'].str.lower()\n",
    "    replacements = [\n",
    "        {\"original\": \"n't\", \"replacement\": \" is not\", \"use_regex\": False},\n",
    "        {\"original\": \"\\'\", \"replacement\": \"\", \"use_regex\": False},\n",
    "        {\"original\": \"\\n\", \"replacement\": \" \", \"use_regex\": False},\n",
    "        {\"original\": \"pre-chorus:\", \"replacement\": \" \", \"use_regex\": False},\n",
    "        {\"original\": \"chorus:\", \"replacement\": \" \", \"use_regex\": False},\n",
    "        {\"original\": \"\\d\\w{2} verse:\", \"replacement\": \"\", \"use_regex\": True}, # Any ver text with a number before (1st, 2nd)\n",
    "        {\"original\": \"\\[intro.*\\]\", \"replacement\": \" \", \"use_regex\": True},\n",
    "        {\"original\": \"\\[verse.*\\]\", \"replacement\": \" \", \"use_regex\": True},\n",
    "        {\"original\": \"\\[\\s*\\]\", \"replacement\": \"\", \"use_regex\": True}, # Empty brackets with no or many spaces\n",
    "    ]\n",
    "\n",
    "    for replacement in replacements:\n",
    "        df = replaceLyricsChars(df, what=replacement[\"original\"], to=replacement[\"replacement\"], regex=replacement[\"use_regex\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = clean_lyrics_df(lyrics_df)\n",
    "lyrics_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the resulting dataframe\n",
    "lyrics_df.to_csv(\"./Resources/cleaned_lyrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " oh baby,\n",
      " how you doing? you know im gonna cut right to the chase some women were made but me,\n",
      " myself i like to think that i was created for a special purpose you know,\n",
      " whats more special than you? you feel me its on baby,\n",
      " lets get lost you do is not need to call into work cause youre the boss for real,\n",
      " want you to show me how you feel i consider myself lucky,\n",
      " thats a big deal why? well,\n",
      " you got the key to my heart but you ai is not gonna need it,\n",
      " id rather you open up my body and show me secrets,\n",
      " you did is not know was inside no need for me to lie its too big,\n",
      " its too wide its too strong,\n",
      " it wo is not fit its too much,\n",
      " its too tough he talk like this cause he can back it up he got a big ego,\n",
      " such a huge ego i love his big ego,\n",
      " its too much he walk like this cause he can back it up usually im humble,\n",
      " right now i do is not choose you can leave with me or you could have the blues some call it arrogant,\n",
      " i call it confident you decide when you find on what im working with damn i know im killing you with them legs better yet them thighs matter a fact its my smile or maybe my eyes boy you a site to see,\n",
      " kind of something like me its too big,\n",
      " its too wide its too strong,\n",
      " it wo is not fit its too much,\n",
      " its too tough i talk like this cause i can back it up i got a big ego,\n",
      " such a huge ego but he love my big ego,\n",
      " its too much i walk like this cause i can back it up i,\n",
      " i walk like this cause i can back it up i,\n",
      " i talk like this cause i can back it up i,\n",
      " i can back it up,\n",
      " i can back it up i walk like this cause i can back it up its too big,\n",
      " its too wide its too strong,\n",
      " it wo is not fit its too much,\n",
      " its too tough he talk like this cause he can back it up he got a big ego,\n",
      " such a huge ego,\n",
      " such a huge ego i love his big ego,\n",
      " its too much he walk like this cause he can back it up ego so big,\n",
      " you must admit i got every reason to feel like im that bitch ego so strong,\n",
      " if you ai is not know i do is not need no beat,\n",
      " i can sing it with piano \n"
     ]
    }
   ],
   "source": [
    "example_text = \"\"\"\n",
    "Oh baby, how you doing?\n",
    "You know I'm gonna cut right to the chase\n",
    "Some women were made but me, myself\n",
    "I like to think that I was created for a special purpose\n",
    "You know, what's more special than you? You feel me\n",
    "It's on baby, let's get lost\n",
    "You don't need to call into work 'cause you're the boss\n",
    "For real, want you to show me how you feel\n",
    "I consider myself lucky, that's a big deal\n",
    "Why? Well, you got the key to my heart\n",
    "But you ain't gonna need it, I'd rather you open up my body\n",
    "And show me secrets, you didn't know was inside\n",
    "No need for me to lie\n",
    "It's too big, it's too wide\n",
    "It's too strong, it won't fit\n",
    "It's too much, it's too tough\n",
    "He talk like this 'cause he can back it up\n",
    "He got a big ego, such a huge ego\n",
    "I love his big ego, it's too much\n",
    "He walk like this 'cause he can back it up\n",
    "Usually I'm humble, right now I don't choose\n",
    "You can leave with me or you could have the blues\n",
    "Some call it arrogant, I call it confident\n",
    "You decide when you find on what I'm working with\n",
    "Damn I know I'm killing you with them legs\n",
    "Better yet them thighs\n",
    "Matter a fact it's my smile or maybe my eyes\n",
    "Boy you a site to see, kind of something like me\n",
    "It's too big, it's too wide\n",
    "It's too strong, it won't fit\n",
    "It's too much, it's too tough\n",
    "I talk like this 'cause I can back it up\n",
    "I got a big ego, such a huge ego\n",
    "But he love my big ego, it's too much\n",
    "I walk like this 'cause I can back it up\n",
    "I, I walk like this 'cause I can back it up\n",
    "I, I talk like this 'cause I can back it up\n",
    "I, I can back it up, I can back it up\n",
    "I walk like this 'cause I can back it up\n",
    "It's too big, it's too wide\n",
    "It's too strong, it won't fit\n",
    "It's too much, it's too tough\n",
    "He talk like this 'cause he can back it up\n",
    "He got a big ego, such a huge ego, such a huge ego\n",
    "I love his big ego, it's too much\n",
    "He walk like this 'cause he can back it up\n",
    "Ego so big, you must admit\n",
    "I got every reason to feel like I'm that bitch\n",
    "Ego so strong, if you ain't know\n",
    "I don't need no beat, I can sing it with piano\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame({\"lyrics\": [example_text]})\n",
    "print(clean_lyrics_df(df)['lyrics'][0].replace(',', ',\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Gutenberg and stopwords databases from the nltk corpus \n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "# Import tokenizers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Import nltk and download  the sentence tokenizer.\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alejandro-\n",
      "[nltk_data]     germosen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/alejandro-\n",
      "[nltk_data]     germosen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/alejandro-\n",
      "[nltk_data]     germosen/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package gutenberg to /Users/alejandro-\n",
      "[nltk_data]     germosen/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'should', 'don', 'aren', 's', 't', \"hasn't\", 'very', \"haven't\", 'what', 'do', 'will', \"you're\", 'ain', 'its', 'wouldn', 'theirs', 'on', 'mustn', \"hadn't\", 'only', 'above', 'no', 'were', 'if', 'to', 'himself', 'which', 'mightn', 'the', 'does', 'there', 'how', 'your', 'so', 'doing', 'these', 'any', 'our', 'haven', 'yourselves', \"wouldn't\", 'was', 'that', 'doesn', 'into', 'other', 'those', 'off', 'for', \"wasn't\", 'had', 'yours', 'isn', 'few', 'having', 'him', 'ours', 'again', \"don't\", 'against', 'until', 'why', 'you', 'hers', 'at', 'can', \"needn't\", 've', 'below', 'further', 'their', 'down', \"mightn't\", 'with', 'wasn', 'because', 'didn', 'weren', 'we', 'after', 'up', 'just', 'been', 'be', 'his', \"it's\", 'her', 'too', 'have', \"that'll\", 'most', 'ourselves', 'each', 'such', \"shouldn't\", 'when', 'are', 'being', 'not', 'o', 'herself', 'they', 'nor', 'a', 'myself', 'has', 'my', 'this', 'ma', 'in', 'itself', 'about', 'is', 'out', \"won't\", 'hasn', 'over', 'once', 'am', 'me', 'of', 'more', \"didn't\", 'from', 'he', \"should've\", \"you'll\", \"aren't\", 'between', 'where', 'an', 'own', 'same', 'yourself', 'y', 'shouldn', 'as', 'here', 'themselves', \"she's\", \"weren't\", 'both', 'd', 'all', 'it', 'she', 'needn', 'before', 'by', 'some', 'couldn', \"doesn't\", 'then', 'who', 'during', \"couldn't\", 'them', 'and', 'than', 'under', 'shan', \"isn't\", \"shan't\", 'through', 'm', 'but', 'll', 'whom', 'while', \"mustn't\", 'now', \"you'd\", \"you've\", 'i', 're', 'or', 'did', 'won', 'hadn'}\n"
     ]
    }
   ],
   "source": [
    "sw = set(stopwords.words('english'))\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Oh baby, how you doing?\n",
      "You know I'm gonna cut right to the chase\n",
      "Some women were made but me, myself\n",
      "I like to think that I was created for a special purpose\n",
      "You know, what's more special than you? You feel me\n",
      "It's on baby, let's get lost\n",
      "You don't need to call into work 'cause you're the boss\n",
      "For real, want you to show me how you feel\n",
      "I consider myself lucky, that's a big deal\n",
      "Why? Well, you got the key to my heart\n",
      "But you ain't gonna need it, I'd rather you open up my body\n",
      "And show me secrets, you didn't know was inside\n",
      "No need for me to lie\n",
      "It's too big, it's too wide\n",
      "It's too strong, it won't fit\n",
      "It's too much, it's too tough\n",
      "He talk like this 'cause he can back it up\n",
      "He got a big ego, such a huge ego\n",
      "I love his big ego, it's too much\n",
      "He walk like this 'cause he can back it up\n",
      "Usually I'm humble, right now I don't choose\n",
      "You can leave with me or you could have the blues\n",
      "Some call it arrogant, I call it confident\n",
      "You decide when you find on what I'm working with\n",
      "Damn I know I'm killing you with them legs\n",
      "Better yet them thighs\n",
      "Matter a fact it's my smile or maybe my eyes\n",
      "Boy you a site to see, kind of something like me\n",
      "It's too big, it's too wide\n",
      "It's too strong, it won't fit\n",
      "It's too much, it's too tough\n",
      "I talk like this 'cause I can back it up\n",
      "I got a big ego, such a huge ego\n",
      "But he love my big ego, it's too much\n",
      "I walk like this 'cause I can back it up\n",
      "I, I walk like this 'cause I can back it up\n",
      "I, I talk like this 'cause I can back it up\n",
      "I, I can back it up, I can back it up\n",
      "I walk like this 'cause I can back it up\n",
      "It's too big, it's too wide\n",
      "It's too strong, it won't fit\n",
      "It's too much, it's too tough\n",
      "He talk like this 'cause he can back it up\n",
      "He got a big ego, such a huge ego, such a huge ego\n",
      "I love his big ego, it's too much\n",
      "He walk like this 'cause he can back it up\n",
      "Ego so big, you must admit\n",
      "I got every reason to feel like I'm that bitch\n",
      "Ego so strong, if you ain't know\n",
      "I don't need no beat, I can sing it with piano\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')\n",
    "# Tokenize the words \n",
    "text = df.loc[0, \"lyrics\"]\n",
    "words = word_tokenize(text)\n",
    "# Get the stem of the words\n",
    "stem = [s_stemmer.stem(word) for word in words]\n",
    "# Get the stopwords\n",
    "sw = set(stopwords.words('english'))\n",
    "# Retrieve only the words that aren't in the stopwords.\n",
    "output = [word.lower() for word in stem if word.lower() not in sw]\n",
    "\n",
    "# first_result = [word.lower() for word in all_words if word.lower() not in sw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh',\n",
       " 'babi',\n",
       " ',',\n",
       " '?',\n",
       " 'know',\n",
       " \"'m\",\n",
       " 'gon',\n",
       " 'na',\n",
       " 'cut',\n",
       " 'right',\n",
       " 'chase',\n",
       " 'women',\n",
       " 'made',\n",
       " ',',\n",
       " 'like',\n",
       " 'think',\n",
       " 'creat',\n",
       " 'special',\n",
       " 'purpos',\n",
       " 'know',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'special',\n",
       " '?',\n",
       " 'feel',\n",
       " \"'s\",\n",
       " 'babi',\n",
       " ',',\n",
       " 'let',\n",
       " \"'s\",\n",
       " 'get',\n",
       " 'lost',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'call',\n",
       " 'work',\n",
       " 'caus',\n",
       " 'boss',\n",
       " 'real',\n",
       " ',',\n",
       " 'want',\n",
       " 'show',\n",
       " 'feel',\n",
       " 'consid',\n",
       " 'lucki',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'big',\n",
       " 'deal',\n",
       " 'whi',\n",
       " '?',\n",
       " 'well',\n",
       " ',',\n",
       " 'got',\n",
       " 'key',\n",
       " 'heart',\n",
       " 'ai',\n",
       " \"n't\",\n",
       " 'gon',\n",
       " 'na',\n",
       " 'need',\n",
       " ',',\n",
       " \"'d\",\n",
       " 'rather',\n",
       " 'open',\n",
       " 'bodi',\n",
       " 'show',\n",
       " 'secret',\n",
       " ',',\n",
       " \"n't\",\n",
       " 'know',\n",
       " 'insid',\n",
       " 'need',\n",
       " 'lie',\n",
       " \"'s\",\n",
       " 'big',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'wide',\n",
       " \"'s\",\n",
       " 'strong',\n",
       " ',',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'fit',\n",
       " \"'s\",\n",
       " 'much',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'tough',\n",
       " 'talk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " 'got',\n",
       " 'big',\n",
       " 'ego',\n",
       " ',',\n",
       " 'huge',\n",
       " 'ego',\n",
       " 'love',\n",
       " 'big',\n",
       " 'ego',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'much',\n",
       " 'walk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " 'usual',\n",
       " \"'m\",\n",
       " 'humbl',\n",
       " ',',\n",
       " 'right',\n",
       " \"n't\",\n",
       " 'choos',\n",
       " 'leav',\n",
       " 'could',\n",
       " 'blue',\n",
       " 'call',\n",
       " 'arrog',\n",
       " ',',\n",
       " 'call',\n",
       " 'confid',\n",
       " 'decid',\n",
       " 'find',\n",
       " \"'m\",\n",
       " 'work',\n",
       " 'damn',\n",
       " 'know',\n",
       " \"'m\",\n",
       " 'kill',\n",
       " 'leg',\n",
       " 'better',\n",
       " 'yet',\n",
       " 'thigh',\n",
       " 'matter',\n",
       " 'fact',\n",
       " \"'s\",\n",
       " 'smile',\n",
       " 'mayb',\n",
       " 'eye',\n",
       " 'boy',\n",
       " 'site',\n",
       " 'see',\n",
       " ',',\n",
       " 'kind',\n",
       " 'someth',\n",
       " 'like',\n",
       " \"'s\",\n",
       " 'big',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'wide',\n",
       " \"'s\",\n",
       " 'strong',\n",
       " ',',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'fit',\n",
       " \"'s\",\n",
       " 'much',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'tough',\n",
       " 'talk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " 'got',\n",
       " 'big',\n",
       " 'ego',\n",
       " ',',\n",
       " 'huge',\n",
       " 'ego',\n",
       " 'love',\n",
       " 'big',\n",
       " 'ego',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'much',\n",
       " 'walk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " ',',\n",
       " 'walk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " ',',\n",
       " 'talk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " ',',\n",
       " 'back',\n",
       " ',',\n",
       " 'back',\n",
       " 'walk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " \"'s\",\n",
       " 'big',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'wide',\n",
       " \"'s\",\n",
       " 'strong',\n",
       " ',',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'fit',\n",
       " \"'s\",\n",
       " 'much',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'tough',\n",
       " 'talk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " 'got',\n",
       " 'big',\n",
       " 'ego',\n",
       " ',',\n",
       " 'huge',\n",
       " 'ego',\n",
       " ',',\n",
       " 'huge',\n",
       " 'ego',\n",
       " 'love',\n",
       " 'big',\n",
       " 'ego',\n",
       " ',',\n",
       " \"'s\",\n",
       " 'much',\n",
       " 'walk',\n",
       " 'like',\n",
       " 'caus',\n",
       " 'back',\n",
       " 'ego',\n",
       " 'big',\n",
       " ',',\n",
       " 'must',\n",
       " 'admit',\n",
       " 'got',\n",
       " 'everi',\n",
       " 'reason',\n",
       " 'feel',\n",
       " 'like',\n",
       " \"'m\",\n",
       " 'bitch',\n",
       " 'ego',\n",
       " 'strong',\n",
       " ',',\n",
       " 'ai',\n",
       " \"n't\",\n",
       " 'know',\n",
       " \"n't\",\n",
       " 'need',\n",
       " 'beat',\n",
       " ',',\n",
       " 'sing',\n",
       " 'piano']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
